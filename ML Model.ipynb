{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2659b61",
   "metadata": {},
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8bd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose best hyperparameters for models\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ca2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in model data\n",
    "data = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# insert code feature and target selection\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6469ee6",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first round of random search\n",
    "\n",
    "# Define the parameter grid\n",
    "rf_param = {\n",
    "    'n_estimators': sp_randint(100, 1000),\n",
    "    'max_depth': sp_randint(2, 8),\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "}\n",
    "\n",
    "# instanciate random forest regressor class\n",
    "rf_reg = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "random_search1 = RandomizedSearchCV(\n",
    "    estimator=rf_reg,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  \n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,  # Cross-validation folds\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV instance\n",
    "random_search1.fit(X_train, y_train)\n",
    "\n",
    "# print best parameters\n",
    "print(\"Best Parameters:\", random_search1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second round of random search\n",
    "# Define the parameter grid\n",
    "rf_param = {\n",
    "    'n_estimators': sp_randint(),  \n",
    "    'max_depth': sp_randint(),   \n",
    "    'min_samples_split': sp_randint(),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "random_search2 = RandomizedSearchCV(\n",
    "    estimator=rf_reg,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  \n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,  # Cross-validation folds\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the RandomizedSearchCV instance\n",
    "random_search2.fit(X_train, y_train)\n",
    "\n",
    "# print best parameters\n",
    "print(\"Best Parameters:\", random_search2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050619d",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for Gradient Boosting Regresssor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e77aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first round of random search\n",
    "\n",
    "# set parameter range\n",
    "gb1_params = {\n",
    "    'n_estimators': sp_randint(50, 200),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': sp_randint(3, 8),\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "}\n",
    "\n",
    "# instanciate GBR\n",
    "gb_reg = GradientBoostingRegressor(random_state = 42)\n",
    "\n",
    "# initialize random search model\n",
    "gb1_random_search = RandomizedSearchCV(\n",
    "    estimator=gb_reg,\n",
    "    param_distributions=gb1_params,\n",
    "    n_iter=10,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit data\n",
    "gb1_random_search.fit(X_train, y_train)\n",
    "\n",
    "# print best parameters\n",
    "print(\"Best Parameters:\", gb1_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01029e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second round of random search\n",
    "\n",
    "# select parameter range\n",
    "gb2_params = {\n",
    "    'n_estimators': sp_randint(),\n",
    "    'learning_rate': uniform(),\n",
    "    'max_depth': sp_randint(),\n",
    "    'min_samples_split': sp_randint(),\n",
    "}\n",
    "\n",
    "# create object for random search \n",
    "gb2_random_search = RandomizedSearchCV(\n",
    "    estimator=gb_reg,\n",
    "    param_distributions=gb2_params,\n",
    "    n_iter=10,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit data\n",
    "gb2_random_search.fit(X_train, y_train)\n",
    "\n",
    "# print best parameters\n",
    "print(\"Best Parameters:\", gb2_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb741f",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fa062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search for logistic regression\n",
    "\n",
    "lr1_params = {\n",
    "    'C': uniform(loc=0, scale=4), \n",
    "    'penalty': ['l1', 'l2'],         \n",
    "    'solver': ['sag','saga'] \n",
    "}\n",
    "\n",
    "# instanciate logistic regression object \n",
    "log_reg = LogisticRegression(random_state = 42)\n",
    "\n",
    "# create object for random search\n",
    "lr1_random_search = RandomizedSearchCV(\n",
    "    log_reg,\n",
    "    param_distributions=lr1_params,\n",
    "    n_iter=10,\n",
    "    cv=3,  \n",
    "    random_state=42, \n",
    "    scoring='accuracy',  \n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "# fit data\n",
    "lr1_random_search.fit(X_train, y_train)\n",
    "\n",
    "# print best parameters\n",
    "print(\"Best Parameters:\", lr1_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96684ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model using voting regressor\n",
    "\n",
    "# choose models based on best parameters\n",
    "rf_model = RandomForest(random_search2.best_params_, random_state = 42)\n",
    "gb_model = GradientBoostingRegressor(gb2_random_search.best_params_, random_state = 42)\n",
    "logreg_model = LogisticRegression(lr1_random_search.best_params_, random_state = 42)\n",
    "\n",
    "# make voting model\n",
    "voting_model = VotingRegressor(estimators = [\n",
    "                                    ('rf', rf_model),\n",
    "                                    ('gb', gb_model),\n",
    "                                    ('log', logreg_model)\n",
    "                                            ]\n",
    "                               random_state = 42)\n",
    "\n",
    "# fit model\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169aec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "voting_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
